{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LM.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "78Ew_p2NEwvJ",
        "colab_type": "text"
      },
      "source": [
        "# Языковые модели\n",
        "\n",
        "Какое слово в последовательности вероятнее: \n",
        "\n",
        "Поезд прибыл на\n",
        "* вокзал\n",
        "* север\n",
        "\n",
        "Какая последовательность вероятнее:\n",
        "* Вокзал прибыл поезд на\n",
        "* Поезд прибыл на вокзал\n",
        "\n",
        "Языковая модель [language model, LM]  позволяет оценить вероятность следующего слова в последовательности  $P(w_n | w_1, \\ldots, w_{n-1})$ и оценить вероятность всей последовательности слов $P(w_1, \\ldots, w_n)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "670nXBLeEwvM",
        "colab_type": "text"
      },
      "source": [
        "### Приложения:\n",
        "* Задачи, в которых нужно обработать сложный и зашумленный вход: распознавание речи, распознавание сканированных и рукописных текстов;\n",
        "* Исправление опечаток\n",
        "* Машинный перевод\n",
        "* Подсказка при наборе "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTpr2mVwEwvQ",
        "colab_type": "text"
      },
      "source": [
        "### Виды моделей:\n",
        "* Счетные модели\n",
        "    * цепи Маркова\n",
        "* Нейронные модели, обычно реккурентные нейронные сети с LSTM/GRU\n",
        "* seq2seq архитектуры"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29Ul3zF7EwvS",
        "colab_type": "text"
      },
      "source": [
        "## Модель $n$-грам\n",
        "\n",
        "Пусть $w_{1:n}=w_1,\\ldots,w_m$ – последовательность слов.\n",
        "\n",
        "Цепное правило:\n",
        "$ P(w_{1:m}) = P(w_1) P(w_2 | w_1) P(w_3 | w_{1:2}) \\ldots P(w_m | w_{1:m-1}) = \\prod_{k=1}^{m} P(w_k | w_{1:k-1}) $\n",
        "\n",
        "Но оценить $P(w_k | w_{1:k-1})$ не легче! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmFQf26OEwvT",
        "colab_type": "text"
      },
      "source": [
        "Переходим к $n$-грамам: $P(w_{i+1} | w_{1:i}) \\approx P(w_{i+1} | w_{i-n:i})  $ , то есть, учитываем $n-1$ предыдущее слово. \n",
        "\n",
        "Модель\n",
        "* униграм: $P(w_k)$\n",
        "* биграм: $P(w_k | w_{k-1})$\n",
        "* триграм: $P(w_k | w_{k-1} w_{k-2})$\n",
        "\n",
        "\n",
        "Т.е. используем Марковские допущения о длине запоминаемой цепочки."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-rlr3ZaEwvU",
        "colab_type": "text"
      },
      "source": [
        "* Вероятность следующего слова в последовательности: $ P(w_{i+1} | w_{1:i}) \\approx P(w_{i-n:i}) $\n",
        "* Вероятность всей последовательности слов: $P(w_{1:n}) = \\prod_{k=1}^l P(w_k | w_{k-n+1: k-1}) $"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iatsWS1vEwvX",
        "colab_type": "text"
      },
      "source": [
        "### Качество модели  $n$-грам\n",
        "\n",
        "Перплексия: насколько хорошо модель предсказывает выборку. Чем ниже значение перплексии, тем лучше.\n",
        "\n",
        "$PP(\\texttt{LM}) = 2 ^ {-\\frac{1}{m} \\log_2 \\texttt{LM} (w_i | w_{1:i-1})}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Jfd7QiLEwva",
        "colab_type": "text"
      },
      "source": [
        "## Счетные языковые модели\n",
        "\n",
        "### ММП оценки вероятностей\n",
        "$ P_{MLE}(w_k | w_{k-n+1:k-1}) = \\frac{\\texttt{count}(w_{k-n+1:k-1} w_k )}{\\texttt{count}(w_{k-n+1:k-1} )} $\n",
        "\n",
        "В модели биграм:\n",
        "\n",
        "$ P_{MLE}(w_k | w_{k-1}) = \\frac{\\texttt{count}(w_{k-1} w_k )}{\\texttt{count}(w_{k-1} )} $\n",
        "\n",
        "Возникает проблема нулевых вероятностей!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8RwTJCHEwvb",
        "colab_type": "text"
      },
      "source": [
        "### Аддитивное сглаживание Лапласа\n",
        "\n",
        "$ P(w_k | w_{k-1}) = \\frac{\\texttt{count}(w_{k-1} w_k ) + \\alpha}{\\texttt{count}(w_{k-1} ) + \\alpha |V|} $"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzPQO_m9Ewvc",
        "colab_type": "text"
      },
      "source": [
        "![AiB](https://raw.githubusercontent.com/artemovae/nlp-course-sberbank/e70ab4acb696c00e170ea91d1bb28fd9ba31c170/img/aib.png)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7v1sq7sLEwve",
        "colab_type": "text"
      },
      "source": [
        "BOS А и Б сидели на трубе EOS\n",
        "\n",
        "BOS А упало Б пропало EOS\n",
        "\n",
        "BOS что осталось на трубе EOS\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "$P($ и $| $ A $) = \\frac{1}{2}$\n",
        "\n",
        "$P($ Б $| $ и $) = \\frac{1}{1}$\n",
        "\n",
        "$P($ трубе $| $ на $) = \\frac{2}{2}$\n",
        "\n",
        "$P($ сидели $| $ Б $) = \\frac{1}{2}$\n",
        "\n",
        "$P($ на $| $ сидели $) = \\frac{1}{2}$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "GJ2SHkp1Ewvg",
        "colab_type": "text"
      },
      "source": [
        "## Модели биграм в NLTK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJ0JfM_KE4dg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "ae2cdf83-3b3a-453a-a95c-313651b1674e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ja3nKPu8Ewvh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import LSTM, TimeDistributed, Bidirectional\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Embedding, Flatten, Dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBvjhLfhEwvt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "42a778ef-d8b6-482e-d95a-90f96f205976"
      },
      "source": [
        "names = [name.strip().lower() for name in open('dinos.txt').readlines()]\n",
        "print(names[:10])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['aachenosaurus', 'aardonyx', 'abdallahsaurus', 'abelisaurus', 'abrictosaurus', 'abrosaurus', 'abydosaurus', 'acanthopholis', 'achelousaurus', 'acheroraptor']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFT_4H1gEwv0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "035e0c84-7256-4665-9987-b6ac69bc306f"
      },
      "source": [
        "chars = [char for name in names for char in name]\n",
        "freq = nltk.FreqDist(chars)\n",
        "\n",
        "print(list(freq.keys()))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['a', 'c', 'h', 'e', 'n', 'o', 's', 'u', 'r', 'd', 'y', 'x', 'b', 'l', 'i', 't', 'p', 'v', 'm', 'g', 'f', 'j', 'k', 'w', 'z', 'q']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MV14Fk1yEwv7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "882aa6f9-bec0-41a1-b80f-33fa180b910f"
      },
      "source": [
        "cfreq = nltk.ConditionalFreqDist(nltk.bigrams(chars))\n",
        "cfreq['a']"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'a': 26,\n",
              "          'b': 32,\n",
              "          'c': 109,\n",
              "          'd': 41,\n",
              "          'e': 48,\n",
              "          'f': 7,\n",
              "          'g': 44,\n",
              "          'h': 21,\n",
              "          'i': 26,\n",
              "          'j': 8,\n",
              "          'k': 22,\n",
              "          'l': 146,\n",
              "          'm': 74,\n",
              "          'n': 354,\n",
              "          'o': 27,\n",
              "          'p': 96,\n",
              "          'q': 3,\n",
              "          'r': 131,\n",
              "          's': 187,\n",
              "          't': 213,\n",
              "          'u': 792,\n",
              "          'v': 34,\n",
              "          'w': 10,\n",
              "          'x': 12,\n",
              "          'y': 14,\n",
              "          'z': 10})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wipYmbzIEwwC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "97b9fa09-55e1-421b-c9f5-9e5cca4c476e"
      },
      "source": [
        "cprob = nltk.ConditionalProbDist(cfreq, nltk.MLEProbDist)\n",
        "print('p(a a) = %1.4f' %cprob['a'].prob('a'))\n",
        "print('p(a b) = %1.4f' %cprob['a'].prob('b'))\n",
        "print('p(a u) = %1.4f' %cprob['a'].prob('u'))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "p(a a) = 0.0105\n",
            "p(a b) = 0.0129\n",
            "p(a u) = 0.3185\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZzezhFVEwwG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "24ea2c9f-3489-4dff-fb8e-c1bf98e147b0"
      },
      "source": [
        "from math import log\n",
        "log(cprob['a'].prob('a')) + log(cprob['a'].prob('b')) + log(cprob['a'].prob('c'))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-12.041317008359863"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MobL2d8VEwwP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "93c8fdf0-18cf-4a8a-c6b5-62b24fbd8358"
      },
      "source": [
        "l = sum([freq[char] for char in freq])\n",
        "print(l)\n",
        "def unigram_prob(char):\n",
        "    return freq[char] / l\n",
        "print('p(a) = %1.4f' % unigram_prob('a'))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18374\n",
            "p(a) = 0.1354\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvssddqlEwwU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "b183af58-5d62-472a-b4a1-f6c692d94665"
      },
      "source": [
        "[bi for bi in nltk.bigrams('aachenosaurus')]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('a', 'a'),\n",
              " ('a', 'c'),\n",
              " ('c', 'h'),\n",
              " ('h', 'e'),\n",
              " ('e', 'n'),\n",
              " ('n', 'o'),\n",
              " ('o', 's'),\n",
              " ('s', 'a'),\n",
              " ('a', 'u'),\n",
              " ('u', 'r'),\n",
              " ('r', 'u'),\n",
              " ('u', 's')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oV5PAYv3Ewwc",
        "colab_type": "text"
      },
      "source": [
        "#### Задание 1\n",
        "\n",
        "1. Напишите функцию для оценки вероятности имени динозавра. \n",
        "2. Найдите наиболее вероятное имя динозавра из данного списка. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uit0sgmNEwwe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def probability_of_name(name):\n",
        "    bigrs = [bi for bi in nltk.bigrams(name)]\n",
        "    prob = 1\n",
        "    for bi in bigrs:\n",
        "        prob *= cprob[bi[0]].prob(bi[1])\n",
        "    return prob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x00Yay11Ewwi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "min_value = 0\n",
        "min_name = ''\n",
        "for name in names:\n",
        "    cur_prob = probability_of_name(name)\n",
        "    if cur_prob > min_value:\n",
        "        min_value = cur_prob\n",
        "        min_name = name"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yln0XamoEwwm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "41647c24-6341-47e7-c2c8-e57c1a218cdf"
      },
      "source": [
        "min_name"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mei'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QFb0AbFEwwx",
        "colab_type": "text"
      },
      "source": [
        "#### Задание 2\n",
        "\n",
        "Напишите функцию для генерации нового имени динозавра фиксированной длины."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uc_1HEZtEww0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_name(start_symbol='a', len_name=10):\n",
        "    name = start_symbol\n",
        "    for _ in range(len_name - 1):\n",
        "        name += cprob[start_symbol].generate()\n",
        "        start_symbol = name[-1]\n",
        "    return name"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNAEpSrREww-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "569d4802-f19e-4ba2-d19d-f60a980157f0"
      },
      "source": [
        "generate_name('b', len_name=20)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bauruloscensaraplboc'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWaLl5r-EwxH",
        "colab_type": "text"
      },
      "source": [
        "## Нейронные языковые модели\n",
        "\n",
        "* Вход: $n$-грамы $w_{1:k}$\n",
        "* $v(w_i)$ – эмбеддинг слова $w_i$, $v(w_i) \\in \\mathbb{R}^{d_{emb}}$, $d_{emb}$ – размерность эмбеддинга, $v(w) = E_{[w]}$\n",
        "* $x = [v(w_1), v(w_2), \\ldots , v(w_k)]$\n",
        "\n",
        "$\\widehat{y} = P(w_i | w_{1:k} ) = \\texttt{LM}(w_{1:k}) = \\texttt{softmax}(hW^2 +b^2)$\n",
        "\n",
        "$h = g(xW^1+b^1)$\n",
        "\n",
        "$w_i \\in V$, $E \\in \\mathbb{R}^{|V|\\times d_{emb}}, W^1 \\in \\mathbb{R}^{k \\cdot d_{emb} \\times d_{hid}}, b^1 \\in \\mathbb{R} ^ {d_{hid}}, W^2 \\in \\mathbb{R}^{d_{hid} \\times |V|}, b^2 \\in \\mathbb{R} ^ {|V|}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeOLmA4OEwxJ",
        "colab_type": "text"
      },
      "source": [
        "![nnlm](https://raw.githubusercontent.com/artemovae/nlp-course-sberbank/e70ab4acb696c00e170ea91d1bb28fd9ba31c170/img/nlm1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RcXoyNBEwxK",
        "colab_type": "text"
      },
      "source": [
        "### Семплирование в нейронных языковых моделях \n",
        "### (Генерация текстов с помощью нейронных языковых моделей)\n",
        "\n",
        "1. Задать начальную последовательность символов длины $k$ (/слов)\n",
        "2. Предсказать распределение вероятностей слов с условием на $k$ предыдущих слов\n",
        "3. 1. Выбрать слово с наибольшей вероятностью\n",
        "3. 2. Выбрать слово по предсказаному распределению\n",
        "4. Сдвинуть окно на одно слово и повторить \n",
        "\n",
        "#### Линейный поиск  (beam search)\n",
        "Всегда помним $h$ наиболее вероятных гипотез:\n",
        "1. Для генерации первого слова в последоватительности генерируем $h$ кандидатов, а не 1\n",
        "2. Генерируем $h \\times h$ кандидатов для второго слова и храним только $h$ наиболее вероятных\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kW8BmP1wEwxO",
        "colab_type": "text"
      },
      "source": [
        "![nnlm](https://raw.githubusercontent.com/artemovae/nlp-course-sberbank/e70ab4acb696c00e170ea91d1bb28fd9ba31c170/img/nlm2.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxrio1HjEwxP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "7e2be93f-2cbb-48ed-dae6-1ece7e7eb107"
      },
      "source": [
        "alphabet = list(set(chars))\n",
        "print('total chars:', len(alphabet))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total chars: 26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uVGD_Z9EwxV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "f95e68c2-2bd8-4c38-eccd-b04a36605645"
      },
      "source": [
        "maxlen = 5\n",
        "step = 1\n",
        "ngrams = []\n",
        "next_chars = []\n",
        "for name in names:\n",
        "    for i in range(0, len(name) - maxlen, step):\n",
        "        ngrams.append(' '.join([char for char in name[i: i + maxlen]]))\n",
        "        next_chars.append(name[i + maxlen])\n",
        "print('nb ngrams:', len(ngrams))\n",
        "print(ngrams[0],next_chars[0])\n",
        "print(ngrams[1],next_chars[1])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nb ngrams: 10701\n",
            "a a c h e n\n",
            "a c h e n o\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzNapRooEwxZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "fde1e8e0-35b3-44c9-e3c7-14981c7020eb"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=len(alphabet))\n",
        "tokenizer.fit_on_texts(ngrams)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(ngrams)\n",
        "X_train = pad_sequences(sequences, maxlen=maxlen)\n",
        "sequences = tokenizer.texts_to_sequences(next_chars)\n",
        "y_train = tokenizer.sequences_to_matrix(sequences)\n",
        "X_train[0]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1,  1, 12, 11,  7], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwEra-ajEwxf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "ecf21184-81a7-4dfe-8d03-6a9e651d626e"
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcZRgkfMEwxj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char_index = tokenizer.word_index\n",
        "index_char = {i: c for c, i in char_index.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvuUvXOJEwxm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "2e881fe0-8c14-4554-e1b6-b066870532d0"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(len(alphabet), 50, input_length=maxlen))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation = 'softmax'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(32, activation = 'softmax'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(len(alphabet), activation = 'softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfKGpGXvEwxp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "ec6b4d5b-0696-4eb9-defe-62b4969110d9"
      },
      "source": [
        "for iteration in range(1, 100):\n",
        "    X_train_shuffled, y_train_shuffled = shuffle(X_train,y_train)\n",
        "    model.fit(X_train_shuffled, y_train_shuffled, batch_size=len(X_train), epochs=1, verbose=0)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeJZhdzfEwxx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds, temperature=0.5):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.choice(range(len(alphabet)), p=preds)\n",
        "    return probas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZ1MhgHEEwx0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "outputId": "2ac4d976-a1ac-4c50-e2dd-9efe1acaa0c4"
      },
      "source": [
        "import random\n",
        "import sys\n",
        "import numpy as np\n",
        "\n",
        "generated = ''\n",
        "seed = 'katya'\n",
        "generated += seed\n",
        "print('----- Generating with seed: \"' + seed + '\"')\n",
        "print(generated)\n",
        "\n",
        "already_used_letters = set()\n",
        "already_used_letters.update(seed)\n",
        "for i in range(8):\n",
        "    sequences = tokenizer.texts_to_sequences([' '.join([char for char in generated[-maxlen:]])])\n",
        "    X_pred = pad_sequences(sequences, maxlen=maxlen)\n",
        "    X_pred = np.array(X_pred)\n",
        "    model.predict(X_pred)\n",
        "    preds = model.predict(X_pred)[0]\n",
        "    while True:\n",
        "        next_index = sample(preds, temperature=0.2)\n",
        "        next_char = index_char[next_index]\n",
        "        if next_char not in already_used_letters:\n",
        "            break\n",
        "    already_used_letters.update(next_char)\n",
        "    generated += next_char\n",
        "    print(generated)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----- Generating with seed: \"katya\"\n",
            "katya\n",
            "katyad\n",
            "katyads\n",
            "katyadsm\n",
            "katyadsmh\n",
            "katyadsmhr\n",
            "katyadsmhrn\n",
            "katyadsmhrnl\n",
            "katyadsmhrnli\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qp_WQtpnEwx5",
        "colab_type": "text"
      },
      "source": [
        "#### Задание 3\n",
        "\n",
        "Измените код выше так, чтобы генерировались панграмы – имена динозавров, не содержащие повторяющихся букв"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZxPFUTCEwx6",
        "colab_type": "text"
      },
      "source": [
        "#### Задание 4\n",
        "\n",
        "Измените функцию семлирования `sample`: добавьте параметр `t`, изпольузуемый для шкалирования вероятностей  `preds`: ```\n",
        "preds /= t\n",
        "``` \n",
        "\n",
        "Как использование этого параметра влияет на генерируемые имена?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7pBab0hEwx7",
        "colab_type": "text"
      },
      "source": [
        "### Рекуррентные нейронные языковые модели\n",
        "\n",
        "RNN позволяют уйти от Марковских допущений и позволяют учитывать предысторию произвольной длины.\n",
        "\n",
        "$x_{1:n} = x_1, x_2, \\ldots, x_n$, $x_i \\in \\mathbb{R}^{d_{in}}$\n",
        "\n",
        "$y_n = RNN(x_{1:n})$, $y_n \\in \\mathbb{R}^{d_{out}}$\n",
        "\n",
        "Для каждого префикса $x_{i:i}$ $y_i$ – выходной вектор.\n",
        "\n",
        "$y_i = RNN(x_{1:i})$\n",
        "\n",
        "$y_{1:n} = RNN^{*}(x_{1:n})$, $y_i \\in \\mathbb{R}^{d_{out}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oSiToNaEwx7",
        "colab_type": "text"
      },
      "source": [
        "![rnn](https://raw.githubusercontent.com/artemovae/nlp-course-sberbank/e70ab4acb696c00e170ea91d1bb28fd9ba31c170/img/rnn1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tC7vLLqEwx9",
        "colab_type": "text"
      },
      "source": [
        "$R$ –  рекурсивная функция с двумя входами: $x_i$ и $s_{i-1}$ (вектор состояния)\n",
        "\n",
        "$RNN^{*}(x_{1:n}, s_0) = y_{1:n}$\n",
        "\n",
        "$y_i = O(s_i)$\n",
        "\n",
        "$s_i = R(s_{i-1}, x_i)$\n",
        "\n",
        "$s_i = R(s_{i-1}, x_i) = g(s_{i-1} W^s + x_i W^x +b)$\n",
        "\n",
        "$x_i \\in \\mathbb{R}^{d_{in}}$, $y_i \\in \\mathbb{R}^{d_{out}}$, $s_i \\in \\mathbb{R}^{d_{out}}$\n",
        "\n",
        "$W^x \\in \\mathbb{R}^{d_{in} \\times d_{in}}$, $W^s \\in \\mathbb{R}^{d_{out} \\times d_{out}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tR9IC3_XEwx-",
        "colab_type": "text"
      },
      "source": [
        "![rnn](https://raw.githubusercontent.com/artemovae/nlp-course-sberbank/e70ab4acb696c00e170ea91d1bb28fd9ba31c170/img/rnn4.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5ey9zhOEwx_",
        "colab_type": "text"
      },
      "source": [
        "#### Обучение RNN: backpropogation through time (BPTT)\n",
        "\n",
        "![rnn](https://raw.githubusercontent.com/artemovae/nlp-course-sberbank/e70ab4acb696c00e170ea91d1bb28fd9ba31c170/img/rnn3.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VL5WwzBaEwyA",
        "colab_type": "text"
      },
      "source": [
        "#### Сценарии использования RNN\n",
        "\n",
        "* Acceptor: только $y_n$, используемый для дальнейшего предсказания / классификации\n",
        "\n",
        "![rnn](https://raw.githubusercontent.com/artemovae/nlp-course-sberbank/e70ab4acb696c00e170ea91d1bb28fd9ba31c170/img/rnn5.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TsSEjVgEwyC",
        "colab_type": "text"
      },
      "source": [
        "* Encoder: только $y_n$\n",
        "\n",
        "![rnn](https://raw.githubusercontent.com/artemovae/nlp-course-sberbank/e70ab4acb696c00e170ea91d1bb28fd9ba31c170/img/rnn5.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8K5GihuEwyD",
        "colab_type": "text"
      },
      "source": [
        "* Transducer: выход $t_i$ для каждого входа $x_{1:i}$ – языковые модели,  sequence labelling\n",
        "\n",
        "![rnn](https://raw.githubusercontent.com/artemovae/nlp-course-sberbank/e70ab4acb696c00e170ea91d1bb28fd9ba31c170/img/rnn2.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpTsFXGgEwyD",
        "colab_type": "text"
      },
      "source": [
        "#### Двунаправленная рекуррентная нейронная сеть\n",
        "\n",
        "$x_{1:n}$ – входная последовательность\n",
        "\n",
        "$s_i^f$ –  \"прошлое / прямое состояние\" – основано на $x_{1:i}$\n",
        "\n",
        "$s_i^b$ –  \"будущее / обратное состояние\" – основано на $x_{n:i}$\n",
        "\n",
        "$y_i = [O(s_i^f), O(s_i^b)] = [y_i^f, y_i^b]$\n",
        "\n",
        "![rnn](https://raw.githubusercontent.com/artemovae/nlp-course-sberbank/e70ab4acb696c00e170ea91d1bb28fd9ba31c170/img/birnn.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWTIglzSEwyE",
        "colab_type": "text"
      },
      "source": [
        "#### Управляемые архитектуры\n",
        "\n",
        "RNN трудно обучать: проблема исчезающего градиента. Уйти от нее помогают управляемые нейроны специального вида: LSTM и GRU.\n",
        "\n",
        "$s_i$ – память нейронной сети. Каждое использование $R$ считывает и видоизменяет всю память. \n",
        "\n",
        "Управляемый доступ к памяти: $g \\in {0,1}^n$:\n",
        "\n",
        "$s_{i+1} \\leftarrow g \\odot x + (1-g) \\odot s_{i}$\n",
        "\n",
        "Дифференцируемое управление:\n",
        "\n",
        "$g \\in \\mathbb{R}^n $:\n",
        "\n",
        "$s_{i+1} \\leftarrow \\sigma(g) \\odot x + (1-g) \\odot s_{i}$\n",
        "\n",
        "http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huqThq_vEwyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "X_names = ['bos ' + ' '.join(name) for name in names]\n",
        "Y_names = [' '.join(name) + ' eos' for name in names]\n",
        "maxlen = max([len(name) for name in names])+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4bJsbdREwyH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=len(alphabet)+2)\n",
        "tokenizer.fit_on_texts(X_names+Y_names)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(X_names)\n",
        "X_train = pad_sequences(sequences, maxlen=maxlen, padding='post')\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(Y_names)\n",
        "Y_train = pad_sequences(sequences, padding='post')\n",
        "\n",
        "Y_train_cat  = [to_categorical(sent, num_classes=len(alphabet)+2) for sent in Y_train]\n",
        "Y_train =  np.asarray(Y_train_cat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gqxFvIvEwyK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "outputId": "a7122431-b117-4d4e-87a5-f9ad5c369c38"
      },
      "source": [
        "print(X_names[0])\n",
        "print(Y_names[0])\n",
        "\n",
        "\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "\n",
        "print(tokenizer.word_index['bos'])\n",
        "print(tokenizer.word_index['eos'])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bos a a c h e n o s a u r u s\n",
            "a a c h e n o s a u r u s eos\n",
            "(1536, 27)\n",
            "(1536, 27, 28)\n",
            "10\n",
            "11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKAL3LJsEwyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char_index = tokenizer.word_index\n",
        "index_char = {i: c for c, i in char_index.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur_L_rAMEwyT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(len(alphabet)+2, 30, input_length=maxlen))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "\n",
        "model.add(Dense(len(alphabet)+2, activation = 'softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "vywPRgtgEwyV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "19e21639-755c-474c-ee39-e18a9c1da6a0"
      },
      "source": [
        "for iteration in range(1, 20):\n",
        "    X_train_shuffled, y_train_shuffled = shuffle(X_train, Y_train)\n",
        "    model.fit(X_train_shuffled, y_train_shuffled, batch_size=len(X_train), epochs=1, verbose = 1)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Epoch 1/1\n",
            "1536/1536 [==============================] - 1s 572us/step - loss: 3.3262 - acc: 0.0679\n",
            "Epoch 1/1\n",
            "1536/1536 [==============================] - 0s 77us/step - loss: 3.3099 - acc: 0.5380\n",
            "Epoch 1/1\n",
            "1536/1536 [==============================] - 0s 75us/step - loss: 3.2926 - acc: 0.5226\n",
            "Epoch 1/1\n",
            "1536/1536 [==============================] - 0s 71us/step - loss: 3.2736 - acc: 0.5206\n",
            "Epoch 1/1\n",
            "1536/1536 [==============================] - 0s 68us/step - loss: 3.2517 - acc: 0.5205\n",
            "Epoch 1/1\n",
            "1536/1536 [==============================] - 0s 66us/step - loss: 3.2255 - acc: 0.5205\n",
            "Epoch 1/1\n",
            "1536/1536 [==============================] - 0s 62us/step - loss: 3.1929 - acc: 0.5205\n",
            "Epoch 1/1\n",
            "1536/1536 [==============================] - 0s 64us/step - loss: 3.1506 - acc: 0.5205\n",
            "Epoch 1/1\n",
            "1536/1536 [==============================] - 0s 67us/step - loss: 3.0939 - acc: 0.5205\n",
            "Epoch 1/1\n",
            "1536/1536 [==============================] - 0s 63us/step - loss: 3.0147 - acc: 0.5205\n",
            "Epoch 1/1\n",
            "1536/1536 [==============================] - 0s 62us/step - loss: 2.9000 - acc: 0.5205\n",
            "Epoch 1/1\n",
            "1536/1536 [==============================] - 0s 64us/step - loss: 2.7295 - acc: 0.5205\n",
            "Epoch 1/1\n",
            "1536/1536 [==============================] - 0s 64us/step - loss: 2.4820 - acc: 0.5205\n",
            "Epoch 1/1\n",
            "1536/1536 [==============================] - 0s 62us/step - loss: 2.1811 - acc: 0.5205\n",
            "Epoch 1/1\n",
            "1536/1536 [==============================] - 0s 64us/step - loss: 1.9267 - acc: 0.5205\n",
            "Epoch 1/1\n",
            "1536/1536 [==============================] - 0s 63us/step - loss: 1.7778 - acc: 0.5205\n",
            "Epoch 1/1\n",
            "1536/1536 [==============================] - 0s 62us/step - loss: 1.7303 - acc: 0.5205\n",
            "Epoch 1/1\n",
            "1536/1536 [==============================] - 0s 64us/step - loss: 1.7578 - acc: 0.5205\n",
            "Epoch 1/1\n",
            "1536/1536 [==============================] - 0s 72us/step - loss: 1.8190 - acc: 0.5205\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qx2LiOaxEwyZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) #/ temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.choice(range(len(alphabet)+2), p = preds)\n",
        "    return probas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlX1tpfrEwyc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "842d5e19-722d-4194-ffa9-70a0e37d8708"
      },
      "source": [
        "generated = ''\n",
        "seed = 'bos'\n",
        "generated += seed + ' '\n",
        "print('----- Generating with seed: \"' + seed + '\"')\n",
        "print(generated)\n",
        "\n",
        "\n",
        "for i in range(7): \n",
        "    sequences = tokenizer.texts_to_sequences([seed])\n",
        "    X_pred = pad_sequences(sequences, maxlen=maxlen, padding = 'post')\n",
        "\n",
        "    preds = model.predict(X_pred, verbose=0)[0]\n",
        "    samples = [sample(p) for p in preds]\n",
        "    next_index = samples[i]\n",
        "    while next_index == 0 or next_index == 10:\n",
        "        samples = [sample(p) for p in preds]\n",
        "        next_index = samples[i]\n",
        "    next_char = index_char[next_index]\n",
        "    generated += next_char + ' '\n",
        "    print(generated)\n",
        "    seed += next_char\n",
        "    if next_char == 'eos':\n",
        "        break\n",
        "    "
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----- Generating with seed: \"bos\"\n",
            "bos \n",
            "bos j \n",
            "bos j n \n",
            "bos j n eos \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiQLbZ7zEwyi",
        "colab_type": "text"
      },
      "source": [
        "#### Задание 5\n",
        "\n",
        "Измените функцию семлирования `sample`: сейчас в ней используется простой выбор наиболее вероятного следующего элемента. Замените его на лучевой поиск [beam search].\n",
        "\n",
        "Как использование этой функции семплирования влияет на генерируемые имена?"
      ]
    }
  ]
}