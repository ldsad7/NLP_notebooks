{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E7ME-ag0hoDA"
   },
   "source": [
    "# Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "colab_type": "code",
    "id": "eVLBU4s9fF-q",
    "outputId": "3116fcaf-0d65-4c62-c4fa-b1070be5aa5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-02-09 13:40:16--  https://www.dropbox.com/s/nd7v1fod89xla6j/vk_texts_with_sources.csv\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.9.1, 2620:100:601f:1::a27d:901\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.9.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/nd7v1fod89xla6j/vk_texts_with_sources.csv [following]\n",
      "--2019-02-09 13:40:17--  https://www.dropbox.com/s/raw/nd7v1fod89xla6j/vk_texts_with_sources.csv\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc9b09c59cba1740041dad76770e.dl.dropboxusercontent.com/cd/0/inline/AbDAzP3QQIl7zVZuPqVAu9arwcIfKUOciqr06geBlCcwqNhBO-316ntiiq8rIACf7d7NO3NnHqowNC2Q2LkJ4gjqkNO4sazvQOI0imrMYwnuAQ3TBNDpxUkCg-siT4AnHHE/file# [following]\n",
      "--2019-02-09 13:40:17--  https://uc9b09c59cba1740041dad76770e.dl.dropboxusercontent.com/cd/0/inline/AbDAzP3QQIl7zVZuPqVAu9arwcIfKUOciqr06geBlCcwqNhBO-316ntiiq8rIACf7d7NO3NnHqowNC2Q2LkJ4gjqkNO4sazvQOI0imrMYwnuAQ3TBNDpxUkCg-siT4AnHHE/file\n",
      "Resolving uc9b09c59cba1740041dad76770e.dl.dropboxusercontent.com (uc9b09c59cba1740041dad76770e.dl.dropboxusercontent.com)... 162.125.9.6, 2620:100:601f:6::a27d:906\n",
      "Connecting to uc9b09c59cba1740041dad76770e.dl.dropboxusercontent.com (uc9b09c59cba1740041dad76770e.dl.dropboxusercontent.com)|162.125.9.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 14406837 (14M) [text/plain]\n",
      "Saving to: ‘vk_texts_with_sources.csv’\n",
      "\n",
      "vk_texts_with_sourc 100%[===================>]  13.74M  62.6MB/s    in 0.2s    \n",
      "\n",
      "2019-02-09 13:40:18 (62.6 MB/s) - ‘vk_texts_with_sources.csv’ saved [14406837/14406837]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.dropbox.com/s/nd7v1fod89xla6j/vk_texts_with_sources.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "qxZMU8CBK664",
    "outputId": "ad5442ea-27c3-4357-8ab9-6249143c49ed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Начальник Главного оперативного управления Ген...</td>\n",
       "      <td>mil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Артиллерийские подразделения общевойскового об...</td>\n",
       "      <td>mil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Подразделения морской пехоты Каспийской флотил...</td>\n",
       "      <td>mil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Команды на всеармейских этапах конкурсов АрМИ-...</td>\n",
       "      <td>mil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>На большом учебно-методическом командирском сб...</td>\n",
       "      <td>mil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text source\n",
       "0  Начальник Главного оперативного управления Ген...    mil\n",
       "1  Артиллерийские подразделения общевойскового об...    mil\n",
       "2  Подразделения морской пехоты Каспийской флотил...    mil\n",
       "3  Команды на всеармейских этапах конкурсов АрМИ-...    mil\n",
       "4  На большом учебно-методическом командирском сб...    mil"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('vk_texts_with_sources.csv', usecols = ['text', 'source'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dYNCAr17MFA3"
   },
   "source": [
    "# Домашнее задание\n",
    "\n",
    "В этом домашнем задании вы будете решать задачу тематической классификации. Даны тексты, опубликованные в нескольких пабликах VK.com, посвященных государственным и муниципальным службам. Формально задача заключается в том, чтобы по тексту ($d$) определить в каком паблике он опубликован, то есть, к какому классу $c$ он принадлежит. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e2EnN-U7MemU"
   },
   "source": [
    "## Задание 1 [1 балл]. Описательные статистики\n",
    "Посчитайте:\n",
    "* количество текстов и количество классов\n",
    "* количество слов (без лемматизации и с лемматизацией) в коллекции\n",
    "* среднюю длину текста в словах и символах\n",
    "* найдите 5 самых частых существительных в текстах каждого паблика \n",
    "\n",
    "*Рекомендуем использовать pandas для расчета описательных статистик.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fTJPlulvQSqQ"
   },
   "source": [
    "Разделите коллекцию текстов на обучающую и тестовую части. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9yCVYfbpNhXd"
   },
   "source": [
    " ## Задание 2 [2 балла]. Классификация по правилам\n",
    " \n",
    " * Разработайте несколько правил вида \"Если встречается слово $w$, то текст относится к паблику $c$\"\n",
    " * Посчитайте, какую точность, полноту, $f$-меру и $accuracy$ вы получаете при классификации по правилам\n",
    " * Получилось ли у вас придумать правило, которое никогда не ошибается?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "22tJKQnaOjie"
   },
   "source": [
    "## Задание 3 [3 балла]. Baseline\n",
    "Используйте стандартный ```sklearn.pipeline``` для классификации текстов: \n",
    "* векторизация \n",
    "* $tf-idf$ взвешивание \n",
    "* ваш любимый метод классификации.\n",
    "\n",
    "\n",
    "Оцените результаты классификации по стандартным мерам качества и проведите анализ ошибок. Для этого рекомендуем визуализировать матрицу ошибок (confusion matrix). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I4m1rDQ3PAqO"
   },
   "source": [
    "## Задание 4 [2 балла]. Снижение размерности\n",
    "Добавьте в ваш ```sklearn.pipeline```  методы снижения размерности:  PCA / LSI / LSA / LDA / другое. Какие методы классификации разумно использовать после снижения размерности? Как изменились результаты классификации после добавления нового шага?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7vVPaaVwPVwg"
   },
   "source": [
    "## Задание 5 [1 балл]. Лемматизация\n",
    "Посмотрите, как влияет лемматизация на качество классификации. Как изменится качество классификации, если вы используете ```CountVectorizer``` на словах или $n$-граммах на лемматизированных текстах?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cdakRHahQp-l"
   },
   "source": [
    "## Задание 6 [3 балла]. Continious bag of words\n",
    "Для baseline решения мы использовали обычное представление текста в виде мешка слов. Попробуйте использовать другие модели представления текста – например, в виде непрерывного мешка слов, то есть, в виде набора эмбеддингов. Для того, чтобы получить вектор текста попробуйте:\n",
    "* усреднить все эмбеддинги слов, входящих в этот текст\n",
    "* усреднить все эмбеддинги слов, входящих в этот текст с $tf-idf$ весами\n",
    "* использовать любую модель эмбеддинга документа.\n",
    "\n",
    "Используйте любую модель эмбеддингов по вашему вкусу. \n",
    "\n",
    "\n",
    "Оцените результаты классификации по стандартным мерам качества и проведите анализ ошибок. Для этого рекомендуем визуализировать матрицу ошибок (confusion matrix). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uyVQ5Gm7Qzcz"
   },
   "source": [
    "## Задание 7 [2 балла]. fastText\n",
    "\n",
    "Используйте ```fastText``` в режиме классификации. Оцените результаты классификации по стандартным мерам качества и проведите анализ ошибок. Для этого рекомендуем визуализировать матрицу ошибок (confusion matrix). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 8 [4 балла]. CNN\n",
    "\n",
    "Реализуйте модель Kim et al (2014) для решения задачи классификации с помощью CNN. Оцените результаты классификации по стандартным мерам качества и проведите анализ ошибок. Для этого рекомендуем визуализировать матрицу ошибок (confusion matrix).\n",
    "Ссылка: Kim Y. Convolutional Neural Networks for Sentence Classification. 2014"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 9 [4 + 2 балла]. RNN\n",
    "\n",
    "(4 балла)Используйте ```RNN``` (BLSTM с какими-то признаками и пулинг поверх) для решения задачи текстовой классификации. Оцените результаты классификации по стандартным мерам качества и проведите анализ ошибок. Для этого рекомендуем визуализировать матрицу ошибок (confusion matrix).\n",
    "\n",
    "За дополнительные 2 балла добавьте в модель символьные признаки - CharCNN или CharRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 10 [8 баллов]. ULMFit\n",
    "\n",
    "Используйте ```ULMFit``` для решения задачи классификации. Оцените результаты классификации по стандартным мерам качества и проведите анализ ошибок. Для этого рекомендуем визуализировать матрицу ошибок (confusion matrix). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_8fKqCD6Q5tW"
   },
   "source": [
    "## Конец\n",
    "Выполните какие-то из предыдущих заданий. Для всех заданий, кроме задания 1 требуется вычислить метрику accuracy метода.\n",
    "\n",
    "Подведите итоги и проведите сравнение всех использованных методов. Какой из них показался вам лучше и почему?\n",
    "\n",
    "**NB!** Задание обязательное вне зависимости от того, сколько из предыдущих пунктов вы выполнили, и дополнительных баллов не дает.\n",
    "\n",
    "\n",
    "Для получения полной оценки за NLP-часть достаточно набрать **20 баллов**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4FkOuR_NiXeT"
   },
   "source": [
    "# Правила сдачи \n",
    "\n",
    "1. Домашняя работа должна быть выполнена в ipynb-тетрадке.\n",
    "2. Сделанную тетрадку нужно отправить ассистенту (ссылка на контакты будет в вики).\n",
    "3. Задание выполняется индивидуально.\n",
    "4. Все вычисления должны быть снабжены пояснениями!\n",
    "5. Дедлайн – 10 июня в 10.00.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
